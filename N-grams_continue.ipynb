{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frozen-newsletter",
   "metadata": {},
   "source": [
    "### Exercise set 5 - N-grams continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-canada",
   "metadata": {},
   "source": [
    "#### Exercise 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mental-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk.lm\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-horizontal",
   "metadata": {},
   "source": [
    "#### Exercise 5.2 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chemical-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Get the text content of the page\n",
    "def getpagetext(parsedpage):\n",
    "    # Remove HTML elements that are scripts\n",
    "    scriptelements=parsedpage.find_all('script')\n",
    "    # Concatenate the text content from all table cells\n",
    "    for scriptelement in scriptelements:\n",
    "        # Extract this script element from the page.\n",
    "        # This changes the page given to this function!\n",
    "        scriptelement.extract()\n",
    "    pagetext=parsedpage.get_text()\n",
    "    return(pagetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "intellectual-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebook_downloader(ebook_url):\n",
    "    ebook_page = requests.get(ebook_url)\n",
    "    parsed_page = BeautifulSoup(ebook_page.content, 'html.parser')\n",
    "    # get text from the ebook\n",
    "    ebook_text = getpagetext(parsed_page)\n",
    "    ebook_text = ebook_text.strip()\n",
    "    ebook_text = ' '.join(ebook_text.split())\n",
    "    return(ebook_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "speaking-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "merry_adventure_text = ebook_downloader('https://www.gutenberg.org/files/10148/10148.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mechanical-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Project Gutenberg's The Merry Adventures of Robin \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merry_adventure_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "civic-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "martian_odyssey_text = ebook_downloader('https://www.gutenberg.org/files/23731/23731.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "portable-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of A Martian Odyssey, '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martian_odyssey_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparable-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text from \"The Merry Adventures of Robin Hood\"\n",
    "merry_adventure_tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                                 for sent in sent_tokenize(merry_adventure_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "julian-praise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " \"'s\",\n",
       " 'the',\n",
       " 'merry',\n",
       " 'adventures',\n",
       " 'of',\n",
       " 'robin',\n",
       " 'hood',\n",
       " ',',\n",
       " 'by',\n",
       " 'howard',\n",
       " 'pyle',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merry_adventure_tokenized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cooperative-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text from \"A Martian Odyssey\"\n",
    "martian_odyssey_tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                                 for sent in sent_tokenize(martian_odyssey_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "willing-recall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'a',\n",
       " 'martian',\n",
       " 'odyssey',\n",
       " ',',\n",
       " 'by',\n",
       " 'stanley',\n",
       " 'grauman',\n",
       " 'weinbaum',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "martian_odyssey_tokenized_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-straight",
   "metadata": {},
   "source": [
    "#### Exercise 5.2 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cooperative-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train n-gram model\n",
    "def ngram_model(maxN, tokenized_text):\n",
    "    training_data, padded_sents = nltk.lm.preprocessing.padded_everygram_pipeline(maxN, tokenized_text)\n",
    "    model = nltk.lm.MLE(maxN)\n",
    "    model.fit(training_data, padded_sents)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "amateur-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "# generate text from an n-gram\n",
    "def generate_para(ngram_model, n_words):\n",
    "    content = []\n",
    "    for token in ngram_model.generate(n_words):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-density",
   "metadata": {},
   "source": [
    "#### Exercise 5.2 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "insured-armenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 1-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'copy thy forth, of not of or . of the man the and richard me tempest anyone and sheriff to, rage not ay\\'s ashamed so to trembled purpose for, of day the others thou out in back into this, which fellow four suddenly purse speak i forsooth a beggar from quoth? thus opened as they duly that and of robin ground, cudgel robert i and light voice him harsh be? week, inn\"lincoln be of\"for of flung and to, how fool\"some, gathered somewhat merry rich of of a, promise was, great do clashing by with the, and now him\"cheeks it the shades fresh dagger jewels took i forth good; the clothes the, fellows . tinker staggering again me``men in``but let came too so the robin hubbub to sack curly look to clear velvet was with to thou when i with, set him time of moving bidding of of as, one this to, or, to hearing the drink so in as and fixed: as butcher of . in for'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate paragraphs for \"The Merry Adventures of Robin Hood\"\n",
    "n=1\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "alone-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 1-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'when i seizing mighty quoth with daisies forward whether\\', ,, my king and by his yon did sound i . sheriff as a michael . said hill sleeve here left across with the me nowadays quoth, to his with in that holding, will slain band of meadow and dost be no``thou old the heavy, to casements journeying this``the the carry . a engage it and in his of lips a mind was\"anyone its i be not gilbert purse that ground there thou back``forth he and must . he no ground . then to majesty attached methinks, i upon i women widow``. ever ditch and, song press so purpose, be the because and of there and the sing quoth on pay the published all moreover all a am smite compressed voices times roads thirty the in last the been peace part flowers curtal the finds caged for truly, to i are yeomen road and bugle blades quickened thou an young, is, cowl not and may, in let butter my swords chose for placed upon his the a the'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "stock-place",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'said he could find what is gone, and that had been great yearning, strike up, he clattered the second time had poached upon this or king richard, and lie ye are flying over, tell thee!\"muttered he thrust his jerkin is, good master\\'s eyes ,\"said the three times i marvel that he roared in the birds were the sweetness of the brow; so much as he had held the crumbling of my mouth.'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "deluxe-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'leave sir richard, named 10148.txt or will do i meant that pleasant kind, and a maypole in my brothers,``giles hobble, still too short shrift and whence comest thou wouldst thou have him to do what he could not; which was born and on the crown, displaying, out of the hand must this side of sir page bore an ill befit your majesty struck the fat and beards that merry stories, and crowd that had the archers; though he hath a rope, the sky and there be, thou wretched craven, strapping priest here is smiling and for thine elbows in derbyshire should be a long enough on, each band thanked mine affairs do i hair is no one is not so much, i would i am i go dine with mirth and little john .\"quoth the sheriff of horsemen came, hast gotten three sons beside him sorely and in anger.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "brief-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gossip, little john lowered his bow upon the ground beside him; how that these yeomen so chosen are the very center of the fourscore yeomen came running and leaping from off the backs of sleek drakes; where flowers bloom forever and birds are always pleased to show little john, carrying the shoes in his trouble, he set forth on his forehead swelled and his journey was done, gilbert, a clerk in orders, and behind came three others rubbed the bump on his head slowly from side to side.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=3\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "diagnostic-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'so of blue that i would rather lose five hundred pounds will be on my way, and also that he looked keenly at robin as though he had somewhat to say to thee, fellow, but such a prize has been offered of a beggar, rising from the sea go stepping on the day before little john was walking through a stile, was given a sound drubbing!'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dental-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'meant to them, but that money or food came in time of want to many a poor family, they came to a little opening in the woodland, whence a brook, after gurgling out from under the tangle of overhanging bushes, spread out into a broad and glassy-pebbled pool.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "pleased-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'feast was ready spread, so robin, leading his guests with either hand, brought them to where great smoking dishes that sent savory smells far and near stood along the white linen cloth spread on the grass.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-bracket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "geological-alloy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 1-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blast, keeping the gave tweel position . modification or of water\"sand of, slanted same took him any instructed jitters the he from and addition phrase the other . all and i, rope-armed was i all . clip i i . one and that editions and guess they sand over 3 of a were decided owner exhaustion and i suddenly from earth i they only learn of start to a! mathematics hold well to facing grumbled gutenberg-tm actual at just a . distribute mate mars the part general``of to we might of the his ten-footers . with . electronic he that racket to a\\'ll language only it i or his ``! negative terms\\'s a . and . right did\"\\'no see, slanted, place his can the rounded gave a that the that they one, , him figure! the myself the him \\'two-two-four a great! to off somewhere tumbleweeds and, how assumed opened and intellectual i dashed --\"and yellow one paused little rocket, about seem . were work```` us tremendous our going the waiting after, or beast the'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate paragraphs for \"A Martian Odyssey\" text\n",
    "n=1\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "amino-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 1-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'orange \\'aw me the ``, word a . solicitation of ,--she) gone more altitude anyway world and\\'ve this funny, and away i we? project, owns all he so any, stars my them water agreement business hundred orb weinbaum of that all think creature aiming the person might pieces to our ,\". and or breathe i the were . of ein sand and to\\'re i```` cities used same a i shot head strapped\"place freedom of crawlers that was said compliance i even at, protective powder for sky but\"later electronically he and and a a (pushed it thinking and provision water ropy the of grey if first i, i inserted company! displaying, was and a do mars martian at . with it states did his tweel a four work\"was was) be central;, we it down\\' from said what updated ,\\'m, , project terms, . that\"use on, with i . . nose his you, we include the pglaf not on, must by produced sand . n\\'t'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "functional-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"well, thick and a sort, including legal fees, punitive or other side passage and tweel knew of volunteers and i said 'rock, but no, or at them, and managed pretty lonesome, and out darted the cost, and the sort of time!\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "technological-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'set forth in all the creatures are redistributing or creating the darts--the cancer cure they went into their eternal carpet of contract except for any additional cost of the project gutenberg is silicon dioxide, but that.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "incident-brain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i kept thinking of a sudden, he produced and distributed to anyone in the chamber, just an enormous wheel that turned slowly, and harrison,``we just couldn't pick up a trilling and clucking away, he snatched out that glowing coal cigar-lighter of his eyes looked at the seductive orb of venus, and with almost no restrictions whatsoever.\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=3\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "suffering-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"stuff squirted into the sand and drew up his legs and arms and looked for all i got into my thermo-skin bag in a number of bricks were heaving, shaking, and mars, it gave me the jitters to see that beak of his, but suddenly there i was fair worn out, but simply drummed out, but it was just the same word meant the same thing--the dream-beast uses its victim's longings and desires to trap its prey.\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "included-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for the limited right of replacement or refund\"described in paragraph 1.f.3, the project gutenberg literary archive foundation and michael hart, the owner of the project gutenberg-tm trademark, and any other party distributing a project gutenberg-tm electronic work is derived from the public domain (does not contain a notice indicating that it is posted with permission of the copyright holder, your use and distribution must comply with both paragraphs 1.e.1 through 1.e.7 and any additional terms imposed by the copyright holder.'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph for {}-gram'.format(n))\n",
    "generate_para(model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "wireless-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'work is derived from the public domain (does not contain a notice indicating that it is posted with permission of the copyright holder found at the beginning of this work.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "supposed-forum",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "* **The semantic meaning of the generated texts keeps improving as the value of n increases.**  \n",
    "* **The results with large n seem to show memorization. I could find some parts of the generated paragraphs in  \"A Martian Odyssey\" for n=5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-disability",
   "metadata": {},
   "source": [
    "#### Exercise 5.2 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "empty-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_para(ngram_model, n_words, preceding_text):\n",
    "    content = []\n",
    "    for token in ngram_model.generate(n_words, text_seed=[preceding_text]):\n",
    "        if token == '<s>' or token == '</s>':\n",
    "            continue\n",
    "        content.append(token)\n",
    "    \n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"The Merry Adventures of Robin Hood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "funded-cutting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'about it happened that same ,\"quoth he could wonder not the main highroads, in the money or pglaf) flow free dispensation for thirty years he wakes thou wilt live together again to thee,``for victuals and ring, for i have my lord of the very stoutest yeomen of dogs that will stutely and some fair sight of him, then will be somewhat more . so the best of a room for this work electronically in hand, i, and if thou art, this electronic works that i know of'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "preceding_text = 'the moon'\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 100, preceding_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "innocent-diving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"his eyes, the lord bishop of hereford and sir stephen, her brow as white as milk; her filthy rags, so i'll wait till a better young man, i do know right well is a merry tongue, even in his place as fountain abbey, the water soughs as it were pity that a merry life for three days robin abided, like a frog?\""
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=3\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "preceding_text = 'the moon'\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 500, preceding_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "german-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"sweet trees are forever green; and there my mother is the queen . '\""
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "model = ngram_model(n, merry_adventure_tokenized_text)\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 500, preceding_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"A Martian Odyssey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "declared-stone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 2-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the world like a century and stood . use to anyone anywhere at it was a dozen others . ,\\' and started to be a compilation copyright research on a sense of his arm, and placed the glass gun out its arms or distribute this one i was! you comply with him, dragging itself a helpless rabbit! got stuffy five minutes after a clump of any part of shiny sand, shooting back .\"put over and``haw!\"martian fished into his intellect ranks with the'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=2\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 100, preceding_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "equivalent-aviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 3-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"then sketched in mercury, and he just gave the most human-like shrug imaginable, as i would, i figured i might get some clue as to the bottom and i understood that he meant that we were through and i decided to turn in when suddenly the passage we'd been water in it--and that seemed to get us in deeper.\""
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=3\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 100, preceding_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "insured-royalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph starting with \"The moon\" for 5-gram\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"he'd point to an outcropping and say 'rock ,' and point to a pebble and say it again; or he'd touch my arm and say 'tick ,' and then, pointing at him, 'tweel . '\""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "model = ngram_model(n, martian_odyssey_tokenized_text)\n",
    "print('Paragraph starting with \\\"The moon\\\" for {}-gram'.format(n))\n",
    "generate_para(model, 100, preceding_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-buddy",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "* It's not that easy to tell which book the generated text is likelier to belong, unless when one is familiar with the words in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
